import asyncio
import io
import traceback
import logging
from docx import Document

logger = logging.getLogger(__name__)

# Import all our services
logger.info("Importing services...")
try:
    logger.info("Importing protocol_parser...")
    from services import protocol_parser
    logger.info("‚úÖ protocol_parser imported")
    
    logger.info("Importing drug_normalizer...")
    from services import drug_normalizer
    logger.info("‚úÖ drug_normalizer imported")
    
    logger.info("Importing regulatory_checker...")
    from services import regulatory_checker
    logger.info("‚úÖ regulatory_checker imported")
    
    logger.info("Importing pubmed_client...")
    from services import pubmed_client
    logger.info("‚úÖ pubmed_client imported")
    
    logger.info("Importing ai_analyzer...")
    from services import ai_analyzer
    logger.info("‚úÖ ai_analyzer imported")
    
except ImportError as e:
    logger.error(f"‚ùå Failed to import services: {e}")
    logger.error(traceback.format_exc())
    raise

# Instantiate clients/services that need it
logger.info("Creating PubMed client...")
pubmed = pubmed_client.PubMedClient()
logger.info("‚úÖ PubMed client created")

async def generate_document_summary(full_text: str) -> str:
    """Uses Gemini to generate a brief summary of the entire document."""
    logger.info("üìù Starting document summary generation...")
    if not full_text:
        logger.warning("‚ùå Empty text for summary generation")
        return "–¢–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø—É—Å—Ç."

    logger.info(f"üìù Generating summary for text of length: {len(full_text)}")
    
    prompt = f"""–ù–∞–ø–∏—à–∏ –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –∫–ª–∏–Ω–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è).
    –£–∫–∞–∂–∏ –æ—Å–Ω–æ–≤–Ω–æ–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–µ, —Ü–µ–ª–µ–≤—É—é –≥—Ä—É–ø–ø—É –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤ –∏ –ø–æ–¥—Ö–æ–¥—ã –∫ –ª–µ—á–µ–Ω–∏—é.

    –¢–µ–∫—Å—Ç:
    ---
    {full_text[:10000]}
    ---
    """
    try:
        logger.info("ü§ñ Sending summary request to Gemini...")
        import google.generativeai as genai
        model = genai.GenerativeModel(
            model_name="gemini-2.5-flash",
            generation_config={"temperature": 0.2, "max_output_tokens": 500}
        )
        response = await model.generate_content_async(prompt)
        summary = response.text.strip()
        logger.info(f"‚úÖ Summary generated: {len(summary)} chars")
        return summary
    except Exception as e:
        logger.error(f"‚ùå Error generating document summary: {e}")
        logger.error(traceback.format_exc())
        traceback.print_exc()
        return "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–±—â–µ–µ —Ä–µ–∑—é–º–µ –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞."


async def process_single_drug(drug_info: dict):
    """
    Processes a single drug through the complete analysis pipeline.
    Returns comprehensive data including normalization, regulatory checks, and literature.
    """
    source_name = drug_info.get("drug_name_source")
    if not source_name:
        logger.warning(f"‚ùå Skipping drug with no source name: {drug_info}")
        return None

    logger.info(f"üíä Processing drug: {source_name}")
    
    try:
        logger.info(f"üîÑ Normalizing drug name: {source_name}")
        normalization_result = await drug_normalizer.normalize_drug(source_name)
        inn_name = normalization_result.get("inn_name")
        logger.info(f"‚úÖ Normalization result: {normalization_result}")
    except Exception as e:
        logger.error(f"‚ùå Normalization failed for {source_name}: {e}")
        logger.error(traceback.format_exc())
        normalization_result = {"inn_name": None, "source": "Error", "confidence": "none"}
        inn_name = None

    if not inn_name:
        logger.warning(f"‚ö†Ô∏è No INN found for {source_name}, returning partial data")
        return {
            "source_data": drug_info,
            "normalization": normalization_result,
            "regulatory_checks": {"regulatory_checks": {}, "dosage_check": {}},
            "pubmed_articles": [],
            "ai_analysis": {
                "ud_ai_grade": "Unknown",
                "ud_ai_justification": "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ú–ù–ù –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞",
                "ai_summary_note": "–¢—Ä–µ–±—É–µ—Ç—Å—è —Ä—É—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞"
            }
        }

    logger.info(f"‚úÖ Found INN: {inn_name}, proceeding with full analysis")
    
    try:
        logger.info(f"üîç Starting regulatory and PubMed checks for {inn_name}")
        regulatory_task = regulatory_checker.check_all_regulators(
            inn_name=inn_name,
            source_dosage=drug_info.get("dosage_source", "")
        )
        pubmed_task = pubmed.search_articles(
            inn_name=inn_name,
            brand_name=source_name,
            disease_context=drug_info.get("context_indication", "")
        )

        logger.info("üîÑ Running regulatory and PubMed tasks in parallel...")
        regulatory_results, pubmed_articles = await asyncio.gather(
            regulatory_task, 
            pubmed_task, 
            return_exceptions=True
        )
        logger.info("‚úÖ Parallel tasks completed")
        
        # Handle exceptions in results
        if isinstance(regulatory_results, Exception):
            logger.error(f"‚ùå Regulatory check failed: {regulatory_results}")
            regulatory_results = {"regulatory_checks": {}, "dosage_check": {}}
            
        if isinstance(pubmed_articles, Exception):
            logger.error(f"‚ùå PubMed search failed: {pubmed_articles}")
            pubmed_articles = []
            
    except Exception as e:
        logger.error(f"‚ùå Error in parallel tasks: {e}")
        logger.error(traceback.format_exc())
        traceback.print_exc()
        regulatory_results = {"regulatory_checks": {}, "dosage_check": {}}
        pubmed_articles = []

    full_drug_data = {
        "source_data": drug_info,
        "normalization": normalization_result,
        "regulatory_checks": regulatory_results,
        "pubmed_articles": pubmed_articles,
    }

    try:
        logger.info(f"üß† Generating final analysis for {source_name}")
        final_analysis = await ai_analyzer.generate_ai_analysis(full_drug_data)
        logger.info(f"‚úÖ Analysis completed for {source_name}")
    except Exception as e:
        logger.error(f"‚ùå Analysis failed for {source_name}: {e}")
        logger.error(traceback.format_exc())
        traceback.print_exc()
        final_analysis = {
            "ud_ai_grade": "Error",
            "ud_ai_justification": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞",
            "ai_summary_note": "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∞–Ω–∞–ª–∏–∑"
        }
        
    full_drug_data["ai_analysis"] = final_analysis
    
    logger.info(f"‚úÖ Completed full analysis for: {source_name}")

    return full_drug_data


async def run_analysis_pipeline(file_content: bytes):
    """
    The main orchestrator for the document analysis pipeline.
    """
    logger.info("üöÄ Starting analysis pipeline")
    logger.info(f"File content size: {len(file_content)} bytes")
    
    file_stream = io.BytesIO(file_content)
    
    try:
        logger.info("üìÑ Loading DOCX document...")
        document = Document(file_stream)
        logger.info("‚úÖ Document loaded successfully")
    except Exception as e:
        logger.error(f"‚ùå Error loading document: {e}")
        logger.error(traceback.format_exc())
        traceback.print_exc()
        return {"error": f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç: {e}"}

    logger.info("üìÑ Extracting text from document...")
    all_text = [p.text for p in document.paragraphs]
    for table in document.tables:
        for row in table.rows:
            for cell in row.cells:
                all_text.append(cell.text)
    full_text = "\n".join(all_text)
    logger.info(f"üìÑ Extracted text length: {len(full_text)} chars")

    if not full_text.strip():
        logger.error("‚ùå Document is empty")
        return {"error": "The document is empty."}

    try:
        # Generate summary and extract drugs concurrently
        logger.info("üîÑ Starting summary and drug extraction")
        summary_task = generate_document_summary(full_text)
        extraction_task = protocol_parser.extract_drugs_from_text(full_text)

        logger.info("‚è≥ Waiting for summary and extraction tasks...")
        document_summary, extracted_drugs = await asyncio.gather(summary_task, extraction_task)
        logger.info(f"‚úÖ Summary and extraction completed. Found {len(extracted_drugs)} drugs")
        logger.info(f"Summary: {document_summary[:100]}...")
    except Exception as e:
        logger.error(f"‚ùå Error in summary/extraction: {e}")
        logger.error(traceback.format_exc())
        traceback.print_exc()
        return {"error": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}"}

    if not extracted_drugs:
        logger.warning("‚ö†Ô∏è No drugs found in document")
        return {
            "document_summary": document_summary,
            "analysis_results": [],
            "message": "No drugs were found in the document."
        }

    logger.info(f"üîÑ Processing {len(extracted_drugs)} extracted drugs")
    for i, drug in enumerate(extracted_drugs):
        logger.info(f"  Drug {i+1}: {drug.get('drug_name_source', 'Unknown')}")

    try:
        logger.info("üîÑ Starting parallel drug analysis...")
        analysis_tasks = [process_single_drug(drug) for drug in extracted_drugs]
        analysis_results = await asyncio.gather(*analysis_tasks, return_exceptions=True)
        logger.info("‚úÖ All drug analysis tasks completed")
        
        # Filter out exceptions and None results
        valid_results = []
        for i, result in enumerate(analysis_results):
            if isinstance(result, Exception):
                logger.error(f"‚ùå Analysis failed for drug {i}: {result}")
            elif result is not None:
                valid_results.append(result)
                logger.info(f"‚úÖ Drug {i+1} analysis successful")
        
        logger.info(f"‚úÖ Pipeline completed. {len(valid_results)} drugs analyzed successfully")
        
        return {
            "document_summary": document_summary,
            "analysis_results": valid_results
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error in drug analysis: {e}")
        logger.error(traceback.format_exc())
        traceback.print_exc()
        return {"error": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –ø—Ä–µ–ø–∞—Ä–∞—Ç–æ–≤: {e}"}

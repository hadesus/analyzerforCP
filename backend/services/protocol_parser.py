import os
import json
import re
import traceback
import logging
import google.generativeai as genai
from dotenv import load_dotenv

logger = logging.getLogger(__name__)

# Load environment variables from .env file
load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), '..', '.env'))

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if not GEMINI_API_KEY:
    logger.error("‚ùå GEMINI_API_KEY not found in environment variables")
    raise ValueError("GEMINI_API_KEY not found in environment variables.")

logger.info("‚úÖ Gemini API key found, configuring...")
genai.configure(api_key=GEMINI_API_KEY)
logger.info("‚úÖ Gemini configured successfully")

# Set up the model with JSON response mode - following demo approach
generation_config = {
    "temperature": 0.1,
    "top_p": 1,
    "top_k": 1,
    "max_output_tokens": 8192,
    "response_mime_type": "application/json",
}

model = genai.GenerativeModel(
    model_name="gemini-2.5-flash",
    generation_config=generation_config
)

def get_extraction_schema():
    """Returns the JSON schema for drug extraction - following demo structure."""
    return {
        "type": "object",
        "properties": {
            "drugs": {
                "type": "array",
                "description": "–°–ø–∏—Å–æ–∫ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö –ª–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤",
                "items": {
                    "type": "object",
                    "properties": {
                        "name": {
                            "type": "string",
                            "description": "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ª–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Å—Ä–µ–¥—Å—Ç–≤–∞"
                        },
                        "innEnglish": {
                            "type": "string", 
                            "description": "–ú–ù–ù –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ"
                        },
                        "dosage": {
                            "type": "string",
                            "description": "–î–æ–∑–∏—Ä–æ–≤–∫–∞"
                        },
                        "route": {
                            "type": "string",
                            "description": "–ü—É—Ç—å –≤–≤–µ–¥–µ–Ω–∏—è"
                        },
                        "frequency": {
                            "type": "string",
                            "description": "–†–µ–∂–∏–º –¥–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è"
                        },
                        "duration": {
                            "type": "string", 
                            "description": "–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç–µ—Ä–∞–ø–∏–∏"
                        }
                    },
                    "required": ["name"]
                }
            }
        },
        "required": ["drugs"]
    }

def get_extraction_prompt(text: str):
    """Returns extraction prompt following demo approach."""
    return f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç –∫–ª–∏–Ω–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞. –ò–∑–≤–ª–µ–∫–∏ –≤—Å–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –ª–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤.
–î–ª—è –∫–∞–∂–¥–æ–≥–æ –ª–µ–∫–∞—Ä—Å—Ç–≤–∞ —É–∫–∞–∂–∏:
- "name": (String) –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ª–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Å—Ä–µ–¥—Å—Ç–≤–∞ (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ, –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ).
- "innEnglish": (String) –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–æ–µ –Ω–µ–ø–∞—Ç–µ–Ω—Ç–æ–≤–∞–Ω–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ (–ú–ù–ù) –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ, –µ—Å–ª–∏ –∏–∑–≤–µ—Å—Ç–Ω–æ –∏–ª–∏ –ª–µ–≥–∫–æ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è. –ï—Å–ª–∏ –Ω–µ—Ç, –æ—Å—Ç–∞–≤—å –ø—É—Å—Ç—ã–º.
- "dosage": (String) –¥–æ–∑–∏—Ä–æ–≤–∫–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "10 –º–≥", "500 –º–≥/—Å—É—Ç").
- "route": (String) –ø—É—Ç—å –≤–≤–µ–¥–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–ø–µ—Ä–æ—Ä–∞–ª—å–Ω–æ", "—Å—É–±–ª–∏–Ω–≥–≤–∞–ª—å–Ω–æ"). –í–ê–ñ–ù–û: –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–π –¢–û–õ–¨–ö–û –∫—Ä–∞—Ç–∫–æ–µ, —Ç–æ—á–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (1-3 —Å–ª–æ–≤–∞), –±–µ–∑ –∫–∞–∫–∏—Ö-–ª–∏–±–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤, –ø–æ—è—Å–Ω–µ–Ω–∏–π, –≤–æ–ø—Ä–æ—Å–æ–≤ –∏–ª–∏ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π –≤ —ç—Ç–æ–º –ø–æ–ª–µ. –ù–∞–ø—Ä–∏–º–µ—Ä: "—Å—É–±–ª–∏–Ω–≥–≤–∞–ª—å–Ω–æ", "–≤–Ω—É—Ç—Ä–∏–º—ã—à–µ—á–Ω–æ", "–º–µ—Å—Ç–Ω–æ (–∞–ø–ø–ª–∏–∫–∞—Ü–∏—è)".
- "frequency": (String) —Ä–µ–∂–∏–º –¥–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, "2 —Ä–∞–∑–∞ –≤ –¥–µ–Ω—å", "–∫–∞–∂–¥—ã–µ 8 —á–∞—Å–æ–≤").
- "duration": (String) –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç–µ—Ä–∞–ø–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "7 –¥–Ω–µ–π", "–¥–æ –∏—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏—è —Å–∏–º–ø—Ç–æ–º–æ–≤").

–¢–µ–∫—Å—Ç –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ (–ø–µ—Ä–≤—ã–µ 100000 —Å–∏–º–≤–æ–ª–æ–≤):
---
{text[:100000]} 
---
–ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å –æ—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å–æ–≥–ª–∞—Å–Ω–æ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ö–µ–º–µ. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–π null –∏–ª–∏ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É."""

def robust_json_parse(raw_text: str) -> dict:
    """
    Robust JSON parsing with multiple fallback strategies.
    """
    if not raw_text or not raw_text.strip():
        return {"drugs": []}
    
    # Clean the text
    cleaned_text = raw_text.strip()
    
    # Remove markdown code blocks
    cleaned_text = re.sub(r'```json\s*', '', cleaned_text)
    cleaned_text = re.sub(r'```\s*$', '', cleaned_text)
    cleaned_text = re.sub(r'^```\s*', '', cleaned_text)
    
    # Try direct parsing first
    try:
        return json.loads(cleaned_text)
    except json.JSONDecodeError as e:
        print(f"Direct JSON parse failed: {e}")
    
    # Strategy 1: Find and fix unterminated strings
    try:
        # Look for common patterns of unterminated strings and fix them
        fixed_text = cleaned_text
        
        # Fix unterminated strings at the end
        if fixed_text.count('"') % 2 != 0:
            # Odd number of quotes - likely unterminated string
            last_quote_pos = fixed_text.rfind('"')
            if last_quote_pos != -1:
                # Check if we're in the middle of a value
                after_quote = fixed_text[last_quote_pos + 1:].strip()
                if after_quote and not after_quote.startswith(',') and not after_quote.startswith('}'):
                    # Add closing quote
                    fixed_text = fixed_text[:last_quote_pos + 1] + '"' + fixed_text[last_quote_pos + 1:]
        
        return json.loads(fixed_text)
    except json.JSONDecodeError:
        pass
    
    # Strategy 2: Find the last complete object
    try:
        # Find all complete JSON objects
        brace_count = 0
        last_complete_pos = -1
        
        for i, char in enumerate(cleaned_text):
            if char == '{':
                brace_count += 1
            elif char == '}':
                brace_count -= 1
                if brace_count == 0:
                    last_complete_pos = i
        
        if last_complete_pos != -1:
            truncated_text = cleaned_text[:last_complete_pos + 1]
            return json.loads(truncated_text)
    except json.JSONDecodeError:
        pass
    
    # Strategy 3: Extract just the drugs array
    try:
        # Look for drugs array pattern with more flexible regex
        drugs_pattern = r'"drugs"\s*:\s*\[(.*?)\]'
        drugs_match = re.search(drugs_pattern, cleaned_text, re.DOTALL)
        
        if drugs_match:
            drugs_content = drugs_match.group(1).strip()
            
            # Try to fix common issues in the drugs array
            if drugs_content:
                # Ensure proper object separation
                if not drugs_content.endswith('}') and not drugs_content.endswith(']'):
                    # Find the last complete object
                    last_brace = drugs_content.rfind('}')
                    if last_brace != -1:
                        drugs_content = drugs_content[:last_brace + 1]
                
                reconstructed = f'{{"drugs": [{drugs_content}]}}'
                return json.loads(reconstructed)
    except (json.JSONDecodeError, AttributeError):
        pass
    
    # Strategy 4: Try to extract individual drug objects
    try:
        # Find all drug objects
        drug_pattern = r'\{[^{}]*"name"\s*:\s*"[^"]*"[^{}]*\}'
        drug_matches = re.findall(drug_pattern, cleaned_text)
        
        if drug_matches:
            drugs = []
            for match in drug_matches:
                try:
                    drug_obj = json.loads(match)
                    drugs.append(drug_obj)
                except json.JSONDecodeError:
                    continue
            
            if drugs:
                return {"drugs": drugs}
    except Exception:
        pass
    
    # Final fallback
    print(f"All JSON parsing strategies failed. Raw text sample: {cleaned_text[:500]}...")
    return {"drugs": []}

async def extract_drugs_from_text(text: str) -> list:
    """
    Uses Gemini to extract drug information from clinical protocol text.
    Simplified approach based on demo version.
    """
    if not text or not text.strip():
        logger.warning("‚ùå Empty text provided")
        return []

    logger.info(f"üìÑ Analyzing text of length: {len(text)}")

    prompt = f"""–ù–∞–π–¥–∏ –≤—Å–µ –ª–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–µ–ø–∞—Ä–∞—Ç—ã –≤ —Ç–µ–∫—Å—Ç–µ –∫–ª–∏–Ω–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞.

–î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞ –≤–µ—Ä–Ω–∏:
- –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞
- –î–æ–∑–∏—Ä–æ–≤–∫—É (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞)
- –ü—É—Ç—å –≤–≤–µ–¥–µ–Ω–∏—è (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω)
- –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

–¢–µ–∫—Å—Ç:
---
{text[:30000]}
---

–û—Ç–≤–µ—Ç—å —Å–ø–∏—Å–∫–æ–º –ø—Ä–µ–ø–∞—Ä–∞—Ç–æ–≤, –∫–∞–∂–¥—ã–π —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
–ü—Ä–µ–ø–∞—Ä–∞—Ç: [–Ω–∞–∑–≤–∞–Ω–∏–µ] | –î–æ–∑–∏—Ä–æ–≤–∫–∞: [–¥–æ–∑–∞] | –ü—É—Ç—å: [–≤–≤–µ–¥–µ–Ω–∏–µ] | –ö–æ–Ω—Ç–µ–∫—Å—Ç: [–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ]"""
    
    try:
        logger.info("ü§ñ Sending request to Gemini...")
        model = genai.GenerativeModel(
            model_name="gemini-2.5-flash",
            generation_config={
                "temperature": 0.1,
                "max_output_tokens": 4000
            }
        )
        
        response = await model.generate_content_async(prompt)
        
        if not response or not response.text:
            logger.error("‚ùå Empty response from Gemini")
            return []
        
        logger.info(f"‚úÖ Gemini response received: {len(response.text)} chars")
        logger.debug(f"Gemini response: {response.text[:500]}...")
        
        # Parse simple text response instead of JSON
        drugs = parse_text_response(response.text)
        logger.info(f"‚úÖ Extracted {len(drugs)} drugs")
        return drugs
        
    except Exception as e:
        logger.error(f"‚ùå Error during Gemini extraction: {e}")
        logger.error(traceback.format_exc())
        traceback.print_exc()
        return []

def parse_text_response(text: str) -> list:
    """Parse simple text response from Gemini."""
    logger.info("üìã Parsing Gemini text response...")
    drugs = []
    lines = text.strip().split('\n')
    logger.info(f"Processing {len(lines)} lines from response")
    
    for line in lines:
        line = line.strip()
        if not line or not '–ü—Ä–µ–ø–∞—Ä–∞—Ç:' in line:
            continue
            
        try:
            # Parse format: –ü—Ä–µ–ø–∞—Ä–∞—Ç: [–Ω–∞–∑–≤–∞–Ω–∏–µ] | –î–æ–∑–∏—Ä–æ–≤–∫–∞: [–¥–æ–∑–∞] | –ü—É—Ç—å: [–≤–≤–µ–¥–µ–Ω–∏–µ] | –ö–æ–Ω—Ç–µ–∫—Å—Ç: [–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ]
            parts = line.split('|')
            
            drug_name = ""
            dosage = ""
            route = ""
            context = ""
            
            for part in parts:
                part = part.strip()
                if part.startswith('–ü—Ä–µ–ø–∞—Ä–∞—Ç:'):
                    drug_name = part.replace('–ü—Ä–µ–ø–∞—Ä–∞—Ç:', '').strip()
                elif part.startswith('–î–æ–∑–∏—Ä–æ–≤–∫–∞:'):
                    dosage = part.replace('–î–æ–∑–∏—Ä–æ–≤–∫–∞:', '').strip()
                elif part.startswith('–ü—É—Ç—å:'):
                    route = part.replace('–ü—É—Ç—å:', '').strip()
                elif part.startswith('–ö–æ–Ω—Ç–µ–∫—Å—Ç:'):
                    context = part.replace('–ö–æ–Ω—Ç–µ–∫—Å—Ç:', '').strip()
            
            if drug_name:
                drug = {
                    "drug_name_source": drug_name,
                    "dosage_source": dosage,
                    "route_source": route,
                    "context_indication": context
                }
                drugs.append(drug)
                logger.info(f"  üìã Found drug: {drug_name}")
                
        except Exception as e:
            logger.error(f"‚ùå Error parsing line '{line}': {e}")
            continue
    
    logger.info(f"‚úÖ Successfully parsed {len(drugs)} drugs from response")
    return drugs
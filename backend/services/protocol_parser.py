import os
import json
import re
import traceback
import logging
import google.generativeai as genai
from dotenv import load_dotenv

logger = logging.getLogger(__name__)

# Load environment variables from .env file
load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), '..', '.env'))

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if not GEMINI_API_KEY:
    logger.error("‚ùå GEMINI_API_KEY not found in environment variables")
    raise ValueError("GEMINI_API_KEY not found in environment variables.")

logger.info("‚úÖ Gemini API key found, configuring...")
genai.configure(api_key=GEMINI_API_KEY)
logger.info("‚úÖ Gemini configured successfully")

async def extract_drugs_from_text(text: str) -> list:
    """
    Uses the EXACT same approach as demo version - unified Gemini extraction.
    This extracts ALL drug information in one powerful prompt.
    """
    if not text or not text.strip():
        logger.warning("‚ùå Empty text provided")
        return []

    logger.info(f"üìÑ Analyzing text of length: {len(text)} using unified demo approach")

    # EXACT same prompt as demo version for maximum accuracy
    prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç –∏–∑ –∫–ª–∏–Ω–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –≤—ã—Å—Ç—É–ø–∏—Ç—å –≤ —Ä–æ–ª–∏ —ç–∫—Å–ø–µ—Ä—Ç–∞ –ø–æ –æ—Ü–µ–Ω–∫–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π.

–í—ã–ø–æ–ª–Ω–∏ —Å–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:
1. –ò–∑–≤–ª–µ–∫–∏ –í–°–ï —É–ø–æ–º—è–Ω—É—Ç—ã–µ –≤ —Ç–µ–∫—Å—Ç–µ –ª–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞.
2. –î–ª—è –ö–ê–ñ–î–û–ì–û –ª–µ–∫–∞—Ä—Å—Ç–≤–∞, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å —Å–ª–µ–¥—É—é—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –≤–∏–¥–µ JSON –æ–±—ä–µ–∫—Ç–∞:
   - "name_author": (String) –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞, –∫–∞–∫ –æ–Ω–æ —É–∫–∞–∑–∞–Ω–æ –≤ —Ç–µ–∫—Å—Ç–µ.
   - "inn": (String) –ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–æ–µ –Ω–µ–ø–∞—Ç–µ–Ω—Ç–æ–≤–∞–Ω–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ (–ú–ù–ù) –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ. –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ—à—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, –Ω–∞–ø–∏—à–∏ "Unknown".
   - "dosage_author": (String) –î–æ–∑–∏—Ä–æ–≤–∫–∞ –∏ —Å–ø–æ—Å–æ–± –≤–≤–µ–¥–µ–Ω–∏—è, –∫–∞–∫ —É–∫–∞–∑–∞–Ω–æ –≤ —Ç–µ–∫—Å—Ç–µ.
   - "route_source": (String) –ü—É—Ç—å –≤–≤–µ–¥–µ–Ω–∏—è (–ø–µ—Ä–æ—Ä–∞–ª—å–Ω–æ, –≤–Ω—É—Ç—Ä–∏–≤–µ–Ω–Ω–æ, –º–µ—Å—Ç–Ω–æ –∏ —Ç.–¥.).
   - "context_indication": (String) –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–ª–∏ –ø–æ–∫–∞–∑–∞–Ω–∏–µ –∏–∑ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞.
   - "formulary_status": (String) –ö—Ä–∞—Ç–∫–∏–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –æ —Å—Ç–∞—Ç—É—Å–µ –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞. –¢–∞–∫ –∫–∞–∫ —É —Ç–µ–±—è –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ –≤–Ω–µ—à–Ω–∏–º –±–∞–∑–∞–º, –Ω–∞–ø–∏—à–∏ "–¢—Ä–µ–±—É–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ –ª–æ–∫–∞–ª—å–Ω—ã–º –∏ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–º —Ñ–æ—Ä–º—É–ª—è—Ä–∞–º (WHO EML, BNF)".
   - "pubmed_suggestion": (String) –ù–∞–ø–∏—à–∏ "–¢—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–∏—Å–∫ –≤ PubMed –ø–æ –∑–∞–ø—Ä–æ—Å—É '{–ú–ù–ù} AND {–æ—Å–Ω–æ–≤–Ω–æ–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–µ –∏–∑ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞}'". –ó–∞–º–µ–Ω–∏ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã.
   - "ud_ai_grade": (String) –¢–≤–æ—è —ç–∫—Å–ø–µ—Ä—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —É—Ä–æ–≤–Ω—è —É–±–µ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤ –ø–æ —à–∫–∞–ª–µ GRADE (High, Moderate, Low, Very Low), –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ —Ç–∏–ø–∏—á–Ω–æ–º –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è –∏–∑ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞.
   - "ai_note": (String) –û—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∞—è (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –∑–∞–º–µ—Ç–∫–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –æ–±–æ–±—â–∞—é—â–∞—è –∫–ª—é—á–µ–≤—ã–µ –∞—Å–ø–µ–∫—Ç—ã –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —ç—Ç–æ–≥–æ –ø—Ä–µ–ø–∞—Ä–∞—Ç–∞ –≤ –¥–∞–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ.

–í–ê–ñ–ù–û: 
- –ò–∑–≤–ª–µ–∫–∞–π –í–°–ï —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –ª–µ–∫–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤, –≤–∫–ª—é—á–∞—è –≤–∏—Ç–∞–º–∏–Ω—ã, –ë–ê–î—ã, –≤–∞–∫—Ü–∏–Ω—ã
- –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ—á–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∏–∑ —Ç–µ–∫—Å—Ç–∞
- –ú–ù–ù –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã—Ö –±–∞–∑–∞—Ö
- –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–π –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É ""
- –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤–∞–ª–∏–¥–Ω—ã–º JSON

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON –æ–±—ä–µ–∫—Ç —Å –∫–ª—é—á–æ–º "drugs", –∫–æ—Ç–æ—Ä—ã–π —è–≤–ª—è–µ—Ç—Å—è –º–∞—Å—Å–∏–≤–æ–º –æ–±—ä–µ–∫—Ç–æ–≤, –æ–ø–∏—Å–∞–Ω–Ω—ã—Ö –≤—ã—à–µ. –ù–µ –¥–æ–±–∞–≤–ª—è–π –Ω–∏–∫–∞–∫–∏—Ö –ø–æ—è—Å–Ω–µ–Ω–∏–π –∏–ª–∏ —Ç–µ–∫—Å—Ç–∞ –¥–æ –∏–ª–∏ –ø–æ—Å–ª–µ JSON.

–¢–µ–∫—Å—Ç –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ (–ø–µ—Ä–≤—ã–µ 50000 —Å–∏–º–≤–æ–ª–æ–≤):
---
{text[:50000]}
---

JSON –æ—Ç–≤–µ—Ç:"""
    
    try:
        logger.info("ü§ñ Sending unified extraction request to Gemini (demo approach)...")
        model = genai.GenerativeModel(
            model_name="gemini-2.5-flash",
            generation_config={
                "temperature": 0.1,
                "max_output_tokens": 8000,
                "response_mime_type": "application/json"
            }
        )
        
        response = await model.generate_content_async(prompt)
        
        if not response or not response.text:
            logger.error("‚ùå Empty response from Gemini")
            return []
        
        logger.info(f"‚úÖ Gemini response received: {len(response.text)} chars")
        logger.debug(f"Raw Gemini response: {response.text[:1000]}...")
        
        # Parse JSON response (same as demo)
        try:
            # Clean the response from possible ```json ... ``` wrappers
            cleaned_response = response.text.strip()
            cleaned_response = re.sub(r'^```json\s*|```\s*$', '', cleaned_response, flags=re.MULTILINE)
            
            parsed_data = json.loads(cleaned_response)
            drugs_list = parsed_data.get("drugs", [])
            
            # Convert demo format to our internal format
            formatted_drugs = []
            for drug in drugs_list:
                if not drug.get("name_author"):
                    continue
                    
                # Map demo fields to our internal structure
                formatted_drug = {
                    "drug_name_source": drug.get("name_author", "").strip(),
                    "inn_name": drug.get("inn", "").strip(),
                    "dosage_source": drug.get("dosage_author", "").strip(),
                    "route_source": drug.get("route_source", "").strip(),
                    "context_indication": drug.get("context_indication", "").strip(),
                    "formulary_status": drug.get("formulary_status", "").strip(),
                    "pubmed_suggestion": drug.get("pubmed_suggestion", "").strip(),
                    "ud_ai_grade": drug.get("ud_ai_grade", "").strip(),
                    "ai_note": drug.get("ai_note", "").strip()
                }
                
                # Skip if no meaningful data
                if formatted_drug["drug_name_source"]:
                    formatted_drugs.append(formatted_drug)
                    logger.info(f"  üìã Found drug: {formatted_drug['drug_name_source']} (INN: {formatted_drug['inn_name']})")
            
            logger.info(f"‚úÖ Successfully extracted {len(formatted_drugs)} drugs using demo approach")
            return formatted_drugs
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå JSON parsing failed: {e}")
            logger.error(f"Raw response: {response.text}")
            
            # Fallback: try to extract drugs from text
            return extract_drugs_from_text_fallback(response.text)
        
    except Exception as e:
        logger.error(f"‚ùå Error during Gemini extraction: {e}")
        logger.error(traceback.format_exc())
        return []

def extract_drugs_from_text_fallback(text: str) -> list:
    """Fallback extraction when JSON parsing fails."""
    logger.info("üîÑ Using fallback text extraction...")
    drugs = []
    
    # Look for drug patterns in text
    lines = text.split('\n')
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # Try to find drug names (common patterns)
        drug_patterns = [
            r'"name_author":\s*"([^"]+)"',
            r'"drug_name_source":\s*"([^"]+)"',
            r'–ø—Ä–µ–ø–∞—Ä–∞—Ç[:\s]+([–ê-–Ø–∞-—èA-Za-z\s\-]+)',
            r'–ª–µ–∫–∞—Ä—Å—Ç–≤–æ[:\s]+([–ê-–Ø–∞-—èA-Za-z\s\-]+)',
            r'([–ê-–Ø][–∞-—è]+(?:\s+[–ê-–Ø][–∞-—è]+)*)\s*(?:\d+\s*–º–≥|\d+\s*–≥|—Ç–∞–±–ª–µ—Ç–∫)'
        ]
        
        for pattern in drug_patterns:
            matches = re.findall(pattern, line, re.IGNORECASE)
            for match in matches:
                drug_name = match.strip()
                if len(drug_name) > 2 and drug_name not in [d["drug_name_source"] for d in drugs]:
                    drugs.append({
                        "drug_name_source": drug_name,
                        "inn_name": "",
                        "dosage_source": "",
                        "route_source": "",
                        "context_indication": "",
                        "formulary_status": "",
                        "pubmed_suggestion": "",
                        "ud_ai_grade": "",
                        "ai_note": ""
                    })
                    logger.info(f"  üìã Fallback found: {drug_name}")
    
    logger.info(f"‚úÖ Fallback extracted {len(drugs)} drugs")
    return drugs

async def generate_document_summary(text: str) -> str:
    """Uses Gemini to generate a brief summary of the entire document."""
    logger.info("üìù Starting document summary generation...")
    if not text:
        logger.warning("‚ùå Empty text for summary generation")
        return "–¢–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø—É—Å—Ç."

    logger.info(f"üìù Generating summary for text of length: {len(text)}")
    
    prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ç–æ–∫–æ–ª –∏ –Ω–∞–ø–∏—à–∏ –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è).

–£–∫–∞–∂–∏:
- –û—Å–Ω–æ–≤–Ω–æ–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–µ –∏–ª–∏ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
- –¶–µ–ª–µ–≤—É—é –≥—Ä—É–ø–ø—É –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤
- –û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã –∫ –ª–µ—á–µ–Ω–∏—é

–¢–µ–∫—Å—Ç –ø—Ä–æ—Ç–æ–∫–æ–ª–∞:
---
{text[:15000]}
---

–†–µ–∑—é–º–µ:"""
    
    try:
        logger.info("ü§ñ Sending summary request to Gemini...")
        model = genai.GenerativeModel(
            model_name="gemini-2.5-flash",
            generation_config={"temperature": 0.2, "max_output_tokens": 500}
        )
        response = await model.generate_content_async(prompt)
        summary = response.text.strip()
        logger.info(f"‚úÖ Summary generated: {len(summary)} chars")
        return summary
    except Exception as e:
        logger.error(f"‚ùå Error generating document summary: {e}")
        return "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—é–º–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞."